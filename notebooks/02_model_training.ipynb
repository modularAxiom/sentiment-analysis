{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initiate Steps For Model Training and Evaluation",
   "id": "bec58e3057fc228e"
  },
  {
   "cell_type": "code",
   "id": "c331c8f98e4d7a10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T21:50:58.457924Z",
     "start_time": "2025-03-14T21:50:55.885737Z"
    }
   },
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "\n",
    "# Load the processed data\n",
    "train_data = pd.read_csv('../data/processed/cleaned_train_data.csv')\n",
    "val_data = pd.read_csv('../data/processed/cleaned_val_data.csv')\n",
    "test_data = pd.read_csv('../data/processed/cleaned_test_data.csv')\n",
    "\n",
    "# Verify data loading\n",
    "print(\"Training data size:\", train_data.shape)\n",
    "print(\"Validation data size:\", val_data.shape)\n",
    "print(\"Test data size:\", test_data.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: (710042, 2)\n",
      "Validation data size: (52581, 2)\n",
      "Test data size: (52582, 2)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Prepare Data for Model Input",
   "id": "35111694f5167d01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T21:55:30.935511Z",
     "start_time": "2025-03-14T21:55:30.885599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Separate features and labels\n",
    "X_train_cleaned = train_data['Review_Text']\n",
    "X_train_cleaned = X_train_cleaned.astype('str')\n",
    "y_train = train_data['Sentiment']\n",
    "\n",
    "X_val_cleaned = val_data['Review_Text']\n",
    "X_val_cleaned = X_val_cleaned.astype('str')\n",
    "y_val = val_data['Sentiment']\n",
    "\n",
    "X_test_cleaned = test_data['Review_Text']\n",
    "X_test_cleaned = X_test_cleaned.astype('str')\n",
    "y_test = test_data['Sentiment']\n",
    "\n",
    "print(\"Features and labels successfully isolated.\")"
   ],
   "id": "9b1079a38ab1a788",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features and labels successfully isolated.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tokenize and Encode Text Data To Prepare It for Transformers",
   "id": "1d1a04c15b0dc9d7"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-14T22:10:47.163918Z",
     "start_time": "2025-03-14T21:57:25.795341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.feature_extraction import get_tokenizer, encode_texts\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = get_tokenizer()\n",
    "\n",
    "# Encode training data\n",
    "X_train_encoded = encode_texts(X_train_cleaned, tokenizer)\n",
    "\n",
    "# Encode the validation data\n",
    "X_val_encoded = encode_texts(X_val_cleaned, tokenizer)\n",
    "\n",
    "# Encode test data\n",
    "X_test_encoded = encode_texts(X_test_cleaned, tokenizer)\n",
    "\n",
    "print(\"The training, validation, and test inputs have been successfully encoded.\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training, validation, and test inputs have been successfully encoded.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Prepare Data for TensorFlow",
   "id": "c109cffe3e1bf310"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:29:13.309967Z",
     "start_time": "2025-03-14T22:29:13.300591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare labels for TensorFlow\n",
    "y_train_tf = y_train.values\n",
    "y_val_tf = y_val.values\n",
    "y_test_tf = y_test.values\n",
    "\n",
    "print(\"Labels for TensorFlow prepared.\")"
   ],
   "id": "4006a54cf1e20471",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels for TensorFlow prepared.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create TensorFlow Datasets and Split Into Batches",
   "id": "2231e47e3d785eb2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T22:30:04.938527Z",
     "start_time": "2025-03-14T22:30:04.850252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define batch size and epochs\n",
    "batch_size = 16\n",
    "epochs = 3\n",
    "\n",
    "# Create TensorFlow datasets for training and evaluation\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(X_train_encoded),\n",
    "    y_train_tf\n",
    ")).shuffle(len(y_train_tf)).batch(batch_size)\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(X_val_encoded),\n",
    "    y_val_tf\n",
    ")).batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(X_test_encoded),\n",
    "    y_test_tf\n",
    ")).batch(batch_size)\n",
    "\n",
    "print(\"TensorFlow Datasets have been successfully prepared.\")"
   ],
   "id": "dbcd7a3848887d9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Datasets have been successfully prepared.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Build, Compile, and Train the Model with Early Stopping",
   "id": "8a348b76d765bbcd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from src.model_training import build_model\n",
    "\n",
    "# Build the model\n",
    "model = build_model()\n",
    "\n",
    "# Define callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks\n",
    ")"
   ],
   "id": "174a52d5663ee978",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model Evaluation on Test Data",
   "id": "4e1149c2531621af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ],
   "id": "9b88e3a75b2f0bac",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
